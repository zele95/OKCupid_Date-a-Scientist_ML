{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from preprocessing import preprocess_text\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "# df = pd.read_csv('profiles.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "[[1 1 1 0 1 1]\n",
      " [0 1 1 1 0 1]]\n",
      "  (0, 5)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "Got:\n",
      "[[1 1 1 0 1 1 'Mjau Vau VAuvau Mjaumjau' 1]\n",
      " [0 1 1 1 0 1 'Mjau Vau' 2]]\n",
      "  text__first text__is text__my text__second text__sentence text__this  \\\n",
      "0           1        1        1            0              1          1   \n",
      "1           0        1        1            1              0          1   \n",
      "\n",
      "      remainder__text_feat2 remainder__numeric_feat  \n",
      "0  Mjau Vau VAuvau Mjaumjau                       1  \n",
      "1                  Mjau Vau                       2  \n",
      "['text__first' 'text__is' 'text__my' 'text__second' 'text__sentence'\n",
      " 'text__this' 'remainder__text_feat2' 'remainder__numeric_feat']\n",
      "  text__first text__is text__my text__second text__sentence text__this  \\\n",
      "0           1        1        1            0              1          1   \n",
      "1           0        1        1            1              0          1   \n",
      "\n",
      "      remainder__text_feat2 remainder__numeric_feat  \n",
      "0  Mjau Vau VAuvau Mjaumjau                       1  \n",
      "1                  Mjau Vau                       2  \n",
      "0    This is my first sentence.\n",
      "Name: text_feat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame(data={'text_feat':['This is my first sentence.','This is my second.'],\n",
    "                        'text_feat2': ['Mjau Vau VAuvau Mjaumjau', 'Mjau Vau'],    \n",
    "                        'numeric_feat':[1,2], \n",
    "                        'target':[3,4]})\n",
    "X = data.loc[:,['text_feat','text_feat2', 'numeric_feat']]\n",
    "y = data.loc[:,'target']\n",
    "\n",
    "# first pipeline \n",
    "text_features = ['text_feat','text_feat2']\n",
    "text_transformer = Pipeline(\n",
    "        steps = [('vec', CountVectorizer())])\n",
    "\n",
    "# wrap in ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('text', text_transformer, 0)], remainder='passthrough')\n",
    "\n",
    "# second pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# single pipeline works as expected\n",
    "X_expected = text_transformer.fit_transform(X['text_feat'])\n",
    "\n",
    "# but this fails\n",
    "X_test = pipeline.fit_transform(X)\n",
    "\n",
    "print('Expected:')\n",
    "print(X_expected.toarray())\n",
    "print(X_expected)\n",
    "print('Got:')\n",
    "print(X_test)\n",
    "print(pd.DataFrame(X_test, columns = pipeline.named_steps['preprocessor'].get_feature_names_out()))\n",
    "feat_names = preprocessor.get_feature_names_out()\n",
    "print(feat_names)\n",
    "print(pd.DataFrame(preprocessor.fit_transform(X),columns = preprocessor.get_feature_names_out()))\n",
    "\n",
    "print(X[:1]['text_feat'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('DL_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d876f14a136bf9116447c888002c305d6a41514ae4dbe09b8bea86ee8a15820"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
